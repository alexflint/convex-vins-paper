\section{Introduction}

Many applications require a mobile device to estimate its position and orientation over time. The Global Positioning System largely solves coarse--scale outdoor localization, but when sub--meter accuracy is required, or if operating in GPS--denied areas, such systems must use on--board sensors to estimate their position. In recent years there has been particular interest in visual inertial navigation (CITE), in which the available sensors are (1) a camera capturing video frames of the environment, (2) an accelerometer measuring the linear acceleration of the device\footnotemark, and (3) a gyro measuring the angular velocity of the device. This particular sensor combination is attractive because the sensors are small, cheap, require relatively little power, and are sufficient to reconstruct the metric trajectory of the device (CITE).

\footnotetext{real accelerometer measurements are distorted by gravity, bias, and noise terms, which will be described later.}

Two main approaches to visual inertial navigation have been proposed within the literature: filtering approaches, in which a covariance is tracked and updated, and optimization approaches, in which a cost is minimized at each time step. Early work within the robotics community pursued the former approach, mostly using the extended Kalman filter (CITE) and the closely related information filter (CITE). These approaches begin by linearizing the measurement equations relating state variables to sensor measurements, then proceed to update a covariance with each incoming sensor reading. Many extensions and improvements to the EKF have been described in recent years, some of which we survey in the next section.

In contrast, optimization--oriented approaches cast visual inertial navigation as an optimization problem in which the device trajectory is parametrized by some number of variables, and one minimizes a cost relating these variables to the sensor measurements (CITE). Having grown out of the computer vision literature on bundle adjustment, this literature almost universally uses quasi--Newton optimizers such as the Levenberg--Marquardt algorithm (CITE), the Dog--leg algorithm (CITE), or, in the case of very large--scale problems, conjugate gradient descent.

In fact both of these approaches can be understood as non--linear least--squares estimators. For globally convex problems, such estimators are guaranteed to converge to the global optimum in the limit of computation (CITE Boyd), but it is well--known that visual inertial navigation problems as commonly formulated are not globally convex, so the only guarantee one has is of eventual convergence to a local optima (CITE). This means that, depending on how an estimator is initialized, it may or may not recover the correct trajectory of the device, even in the limit of an infinite number of noise--free measurements, and even given the usual excitation requirements (CITE).

Furthermore, this is no mere theoretical technicality: practical visual inertial navigation systems are frequently hampered by failure to converge to the desired optimum, which is caused ultimately by the non--convexity of the problem (CITE). This issue is particularly severe during initialization, in which one seeks an estimate for the state of the device at time zero when no previous estimate is available to bootstrap from. The initialization problem has been recognized as a key unsolved problem in the field (CITE). In fact many state--of--the--art systems currently require a stationary period of several seconds at the beginning of a trajectory in order to overcome this issues (CITE), but as well as being inconvenient, such stipulations are impossible in passive contexts where one cannot request that the device undergo specific motion patterns.

In this paper we present a globally convex formulation for visual inertial navigation, allowing us to apply modern convex optimization tools with well--understood convergence guarantees. This allows us to overcome the initialization problem since at time zero we can formulate and solve a single convex optimization problem and be assured of convergence to the global optimum without requiring a previous estimate from which to bootstrap. Our work builds on ideas recently proposed within the computer vision literature where second--order cone programming (SOCP) has been applied to triangulation and resection problems (CITE).

Our approach is as follows. We begin by tracking image features across two or more video frames. Next, inspired by recent work on continuous--time SLAM (CITE), we parametrize the device trajectory as a cubic B--spline in three dimensions. Our optimization problem is then formulated over the spline control points, plus the inertial biases, the direction of gravity, and the coordinates for $N$ unknown landmarks corresponding to tracked image features. The continuous--time trajectory parametrization allows us to write closed--form expressions for the predicted acceleration and angular velocity measurements as a function of the spline control points, as well as the image projections of the estimated landmarks. Next we define a residual vector consisting of the difference between the expected and observed sensor readings, for both the visual and inertial sensors. While least--squares algorithms would minimize the $L_2$ norm of this vector, we opt instead to minimize the $L_\infty$ norm. This means we are no longer minimizing the true negative log--likelihood, but the fact that we can minimize this cost globally makes this concession bearable. Furthermore, we show in the experimental section that in practice our minimization results in an excellent approximation to the $L_2$ minimizer. Finally we solve the $L_\infty$ minimization as a sequence of SOCP problems.

The remainder of this paper is organized as follows. The next section surveys existing work related to our own, then section 3 presents our convex formulation for the visual inertial navigation problem. Section 4 describes the SOCP optimization algorithm that we use to solve this problem, then section 5 presents experimental results using real and simulated data. Finally, section 6 concludes the paper.
